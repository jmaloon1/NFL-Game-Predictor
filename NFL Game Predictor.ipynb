{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     8,
     40,
     72
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "header_name = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'\n",
    "acronym_to_town_dict = {'ARI': 'Arizona',\n",
    "                        'ATL': 'Atlanta',\n",
    "                        'BAL': 'Baltimore',\n",
    "                        'BUF': 'Buffalo',\n",
    "                        'CAR': 'Carolina',\n",
    "                        'CHI': 'Chicago',\n",
    "                        'CIN': 'Cincinnati',\n",
    "                        'CLE': 'Cleveland',\n",
    "                        'DAL': 'Dallas',\n",
    "                        'DEN': 'Denver',\n",
    "                        'DET': 'Detroit',\n",
    "                        'GB': 'Green Bay',\n",
    "                        'HOU': 'Houston',\n",
    "                        'IND': 'Indianapolis',\n",
    "                        'JAX': 'Jacksonville',\n",
    "                        'KC': 'Kansas City',\n",
    "                        'LAC': 'L.A. Chargers',\n",
    "                        'LAR': 'L.A. Rams',\n",
    "                        'MIA': 'Miami',\n",
    "                        'MIN': 'Minnesota',\n",
    "                        'NE': 'New England',\n",
    "                        'NO': 'New Orleans',\n",
    "                        'NYG': 'N.Y. Giants',\n",
    "                        'NYJ': 'N.Y. Jets',\n",
    "                        'OAK': 'Oakland',\n",
    "                        'PHI': 'Philadelphia',\n",
    "                        'PIT': 'Pittsburgh',\n",
    "                        'SEA': 'Seattle',\n",
    "                        'SF': 'San Francisco',\n",
    "                        'TB': 'Tampa Bay',\n",
    "                        'TEN': 'Tennessee',\n",
    "                        'WSH': 'Washington'}\n",
    "town_to_acronym_dict = {'Arizona': 'ARI',\n",
    "                        'Atlanta': 'ATL',\n",
    "                        'Baltimore': 'BAL',\n",
    "                        'Buffalo': 'BUF',\n",
    "                        'Carolina': 'CAR',\n",
    "                        'Chicago': 'CHI',\n",
    "                        'Cincinnati': 'CIN',\n",
    "                        'Cleveland': 'CLE',\n",
    "                        'Dallas': 'DAL',\n",
    "                        'Denver': 'DEN',\n",
    "                        'Detroit': 'DET',\n",
    "                        'Green Bay': 'GB',\n",
    "                        'Houston': 'HOU',\n",
    "                        'Indianapolis': 'IND',\n",
    "                        'Jacksonville': 'JAX',\n",
    "                        'Kansas City': 'KC',\n",
    "                        'L.A. Chargers': 'LAC',\n",
    "                        'L.A. Rams': 'LAR',\n",
    "                        'Miami': 'MIA',\n",
    "                        'Minnesota': 'MIN',\n",
    "                        'New England': 'NE',\n",
    "                        'New Orleans': 'NO',\n",
    "                        'N.Y. Giants': 'NYG',\n",
    "                        'N.Y. Jets': 'NYJ',\n",
    "                        'Oakland': 'OAK',\n",
    "                        'Philadelphia': 'PHI',\n",
    "                        'Pittsburgh': 'PIT',\n",
    "                        'Seattle': 'SEA',\n",
    "                        'San Francisco': 'SF',\n",
    "                        'Tampa Bay': 'TB',\n",
    "                        'Tennessee': 'TEN',\n",
    "                        'Washington': 'WSH'}\n",
    "nickname_to_town_dict = {'Cardinals': 'Arizona',\n",
    "                        'Falcons': 'Atlanta',\n",
    "                        'Ravens': 'Baltimore',\n",
    "                        'Bills': 'Buffalo',\n",
    "                        'Panthers': 'Carolina',\n",
    "                        'Bears': 'Chicago',\n",
    "                        'Bengals': 'Cincinnati',\n",
    "                        'Browns': 'Cleveland',\n",
    "                        'Cowboys': 'Dallas',\n",
    "                        'Broncos': 'Denver',\n",
    "                        'Lions': 'Detroit',\n",
    "                        'Packers': 'Green Bay',\n",
    "                        'Texans': 'Houston',\n",
    "                        'Colts': 'Indianapolis',\n",
    "                        'Jaguars': 'Jacksonville',\n",
    "                        'Chiefs': 'Kansas City',\n",
    "                        'Chargers': 'L.A. Chargers',\n",
    "                        'Rams': 'L.A. Rams',\n",
    "                        'Dolphins': 'Miami',\n",
    "                        'Vikings': 'Minnesota',\n",
    "                        'Patriots': 'New England',\n",
    "                        'Saints': 'New Orleans',\n",
    "                        'Giants': 'N.Y. Giants',\n",
    "                        'Jets': 'N.Y. Jets',\n",
    "                        'Raiders': 'Oakland',\n",
    "                        'Eagles': 'Philadelphia',\n",
    "                        'Steelers': 'Pittsburgh',\n",
    "                        'Seahawks': 'Seattle',\n",
    "                        '49ers': 'San Francisco',\n",
    "                        'Buccaneers': 'Tampa Bay',\n",
    "                        'Titans': 'Tennessee',\n",
    "                        'Redskins': 'Washington'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0,
     63,
     71,
     83,
     150,
     206,
     273,
     292,
     303,
     316,
     371,
     382,
     401,
     421,
     433,
     449,
     469,
     492,
     537
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initial_538_predictions(week_num):\n",
    "    \"\"\"Creates dataframe with initial values from 538\n",
    "    Args:\n",
    "        week_num: week number of games\n",
    "    Returns:\n",
    "        dataframe of 538 predictions\n",
    "    \"\"\"\n",
    "    df_columns = ['week', 'date', 'team', '538 win%']\n",
    "    df = pd.DataFrame(columns=df_columns)\n",
    "    \n",
    "    output_file = 'z:\\python_projects\\aaa.exe'\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://projects.fivethirtyeight.com/2019-nfl-predictions/games/?ex_cid=rrpromo'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "    # Finding year of predictions\n",
    "    for timestamp in soup.findAll('div', attrs={'class': 'container'}):\n",
    "        for year in timestamp.findAll('div', attrs={'id': 'intro'}):\n",
    "            year = int(year.h1.get_text()[0:5])\n",
    "\n",
    "    # Gathering data\n",
    "    for week in soup.findAll('section', attrs={'class': 'week'}):\n",
    "        if week.get_text()[5] == str(week_num):\n",
    "            for date in week.findAll('div', attrs={'class': 'days'}):\n",
    "                for weekday in date.findAll('div', attrs={'class': 'day'}):  \n",
    "                    for game in weekday.findAll('div', attrs={'class': 'game'}):\n",
    "\n",
    "                        # Finding date of each game  \n",
    "                        for h4 in weekday.findAll('h4', attrs={'class': 'h4'}):\n",
    "                            date = h4.get_text().strip()\n",
    "                            date = date.split(', ')[1]\n",
    "                            date = date[0:3] + date[4:] + ' ' + str(year)\n",
    "                            date = datetime.datetime.strptime(date, '%b %d %Y')\n",
    "                            year = date.year\n",
    "                            month = date.month\n",
    "                            day = date.day\n",
    "                            date = date.strftime('%m/%d/%Y')\n",
    "\n",
    "                        # Finding data for each game\n",
    "                        for game_body in game.findAll('table', attrs={'class': 'game-body'}):           \n",
    "                            for num_teams, matchup in enumerate(game_body.findAll('tr', attrs={'class': 'tr'})):\n",
    "                                squad = matchup.find('td', attrs={'class': 'td text team'})\n",
    "                                win_percentage = matchup.find('td', attrs={'class': 'td number chance'}).get_text().strip()\n",
    "\n",
    "                                if squad:\n",
    "                                    team = squad.get_text().strip()\n",
    "                                    result = ''\n",
    "                                    \n",
    "                                    if num_teams == 0:\n",
    "                                        df = df.append(pd.Series([week_finder(datetime.date(year, month, day)),\n",
    "                                                                  date, team, win_percentage], index=df.columns),\n",
    "                                                                  ignore_index=True)\n",
    "                                    else:\n",
    "                                        df = df.append(pd.Series([week_finder(datetime.date(year, month, day)),\n",
    "                                                                  '', team, win_percentage], index=df.columns),\n",
    "                                                                  ignore_index=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df, year\n",
    "    \n",
    "def getting_spreadsheet(file_name):\n",
    "    \"\"\"Loads spreadsheet\n",
    "    Args:\n",
    "        file_name: path of file\n",
    "    Returns:\n",
    "        dataframe of data\n",
    "    \"\"\"\n",
    "    return(pd.read_csv(file_name))\n",
    "def separating_games(df):\n",
    "    \"\"\"Separates old games and new games\n",
    "    Args:\n",
    "        df: dataframe of data\n",
    "    Returns:\n",
    "        old_games: games with results already\n",
    "        current_game: games without results\n",
    "    \"\"\"\n",
    "    old_games = df[df['result'] != '']\n",
    "    old_games_index = df[df['result'] != ''].index \n",
    "    current_games = df.drop(old_games_index)\n",
    "    return old_games, current_games\n",
    "def predictions_538(week_num):\n",
    "    \"\"\"Loads 538 predictions\n",
    "    Args:\n",
    "        week_num: week number of games\n",
    "    Returns:\n",
    "        df: dataframe with 538 predictions\n",
    "        year: year of games. Needed for Vegas odds\n",
    "    \"\"\"\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://projects.fivethirtyeight.com/2019-nfl-predictions/games/?ex_cid=rrpromo'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "    cols = ['week', 'date', 'team', '538 win%']\n",
    "    blank_rows = ['']*(len(df.columns)-3)\n",
    "    cols.extend(blank_rows)\n",
    "    predictions = pd.DataFrame(columns=cols)\n",
    "\n",
    "    # Finding year of predictions\n",
    "    for timestamp in soup.findAll('div', attrs={'class': 'container'}):\n",
    "        for year in timestamp.findAll('div', attrs={'id': 'intro'}):\n",
    "            year = int(year.h1.get_text()[0:5])\n",
    "\n",
    "    # Gathering data\n",
    "    for week in soup.findAll('section', attrs={'class': 'week'}):\n",
    "        if week.h3.get_text()[-2:].strip() == str(week_num):\n",
    "            for date in week.findAll('div', attrs={'class': 'days'}):\n",
    "                for weekday in date.findAll('div', attrs={'class': 'day'}):  \n",
    "                    for game in weekday.findAll('div', attrs={'class': 'game'}):\n",
    "\n",
    "                        # Finding date of each game  \n",
    "                        for h4 in weekday.findAll('h4', attrs={'class': 'h4'}):\n",
    "                            date = h4.get_text().strip()\n",
    "                            date = date.split(', ')[1]\n",
    "                            date = date[0:3] + ' ' + date[-2:] + ' ' + str(year)\n",
    "                            date = datetime.datetime.strptime(date, '%b %d %Y')\n",
    "                            year = date.year\n",
    "                            month = date.month\n",
    "                            day = date.day\n",
    "                            date = date.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "                        # Finding data for each game\n",
    "                        for game_body in game.findAll('table', attrs={'class': 'game-body'}):           \n",
    "                            for num_teams, matchup in enumerate(game_body.findAll('tr', attrs={'class': 'tr'})):\n",
    "                                squad = matchup.find('td', attrs={'class': 'td text team'})\n",
    "                                win_percentage = matchup.find('td', attrs={'class': 'td number chance'}).get_text().strip()\n",
    "\n",
    "                                if squad:\n",
    "                                    team = squad.get_text().strip()\n",
    "                                    result = ''\n",
    "                                    \n",
    "                                    if num_teams == 0:\n",
    "                                        row_data = [week_finder(datetime.date(year, month, day)), date, team, win_percentage]\n",
    "                                        row_data.extend(blank_rows)\n",
    "                                        \n",
    "                                        predictions = predictions.append(pd.Series(row_data, index=predictions.columns), \n",
    "                                                                         ignore_index=True)\n",
    "                                    else:\n",
    "                                        row_data = [week_finder(datetime.date(year, month, day)), date, team, win_percentage]\n",
    "                                        row_data.extend(blank_rows)\n",
    "\n",
    "                                        predictions = predictions.append(pd.Series(row_data, index=predictions.columns), \n",
    "                                                                         ignore_index=True)\n",
    "  \n",
    "    return predictions, year\n",
    "def predictions_fox(df):\n",
    "    \"\"\"Loads fox predictions\n",
    "    Args:\n",
    "    df: dataframe of data that will be merged with\n",
    "    Returns:\n",
    "        df: dataframe including Fox predictions\n",
    "    \"\"\"\n",
    "    predictions_columns = ['week', 'team', 'Fox win%']\n",
    "    predictions = pd.DataFrame(columns=predictions_columns)\n",
    "\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://www.foxsports.com/nfl/predictions'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "    for week in soup.findAll('span', attrs={'class': 'wisbb_pageInfoSecondaryText'}):\n",
    "        week_num = int(week.get_text().strip()[5:])\n",
    "\n",
    "\n",
    "    for matchup in soup.findAll('div', attrs={'class': 'wisbb_predictionChip'}):\n",
    "        for num, team_name in enumerate(matchup.findAll('span', attrs={'class': 'wisbb_teamName'})):\n",
    "            if num == 0:\n",
    "                away_team = team_name.get_text().strip()\n",
    "            elif num == 1:\n",
    "                home_team = team_name.get_text().strip()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        for num, fox_predictions in enumerate(matchup.findAll('span', attrs={'class': 'wisbb_predData'})):\n",
    "            prediction_text = fox_predictions.get_text()\n",
    "            team_acronym = fox_predictions.get_text()[0:3].strip()\n",
    "            if team_acronym in acronym_to_town_dict and len(prediction_text)>4 and num ==1:\n",
    "                if acronym_to_town_dict[team_acronym] == nickname_to_town_dict[away_team]:\n",
    "                    away_win_percentage_int = int(round(float(prediction_text.split('(')[1][:-2])))\n",
    "                    away_win_percentage_string = str(away_win_percentage_int) + '%'\n",
    "                    home_win_percentage_int = 100 - away_win_percentage_int\n",
    "                    home_win_percentage_string = str(home_win_percentage_int) + '%'\n",
    "\n",
    "                elif acronym_to_town_dict[team_acronym] == nickname_to_town_dict[home_team]:\n",
    "                    home_win_percentage_int = int(round(float(prediction_text.split('(')[1][:-2])))\n",
    "                    home_win_percentage_string = str(home_win_percentage_int) + '%'\n",
    "                    away_win_percentage_int = 100 - home_win_percentage_int\n",
    "                    away_win_percentage_string = str(away_win_percentage_int) + '%'\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                predictions = predictions.append(pd.Series([week_num, nickname_to_town_dict[away_team], away_win_percentage_string],\n",
    "                                             index=predictions.columns), ignore_index=True)\n",
    "                predictions = predictions.append(pd.Series([week_num, nickname_to_town_dict[home_team], home_win_percentage_string],\n",
    "                                             index=predictions.columns), ignore_index=True)\n",
    "\n",
    "    df = pd.merge(predictions, df)\n",
    "    \n",
    "    return df\n",
    "def loading_odds(df, year):\n",
    "    \"\"\"Loads odds to spreadsheet\n",
    "    Args:\n",
    "        df: dataframe that odds will be written to\n",
    "        year: year that will be used to gather the dates of the games\n",
    "    Returns:\n",
    "        dataframe of datawith odds\n",
    "    \"\"\"\n",
    "    names = ['Open', 'odds','Westgate','MGM Mirage', 'betMGM',\n",
    "             'William Hill', 'CG Technology', 'Circa Sports','Stations']\n",
    "    book = pd.DataFrame(columns=names)\n",
    "    output_file = 'z:\\python_projects\\aaa.exe'\n",
    "    temp_away_list = []\n",
    "    temp_home_list = []\n",
    "    teams_list = []\n",
    "    dates_list = []\n",
    "    URL = 'http://www.vegasinsider.com/nfl/odds/las-vegas/money/'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "    for gameboard in soup.findAll('table', attrs={'class': 'viBodyContainerTble'}):\n",
    "        for num, games in enumerate(gameboard.findAll('td', attrs={'class': 'viBodyBorderNorm'})):\n",
    "            for game_info in games.findAll('td'):  \n",
    "                for date in game_info.findAll('span', attrs={'class': 'cellTextHot'}):\n",
    "                    date = date.get_text().split()[0]\n",
    "                    month = date.split('/')[0]\n",
    "                    day = date.split('/')[1]\n",
    "\n",
    "                    date = str(month) + '/' + str(day) + '/' + str(year)\n",
    "                    dates_list.extend([date, date])\n",
    "\n",
    "                for team_name in game_info.findAll('a', attrs={'class': 'tabletext'}):\n",
    "                    teams_list.append(team_name.get_text())\n",
    "\n",
    "            for num, spread in enumerate(games.findAll('td',attrs={'class': \n",
    "                                                                  ['viCellBg1 cellTextNorm cellBorderL1 center_text nowrap',\n",
    "                                                                   'viCellBg1 cellTextHot cellBorderL1 center_text nowrap',\n",
    "                                                                   'viCellBg2 cellTextNorm cellBorderL1 center_text nowrap',\n",
    "                                                                   'viCellBg2 cellTextHot cellBorderL1 center_text nowrap']})):           \n",
    "                spread_text = spread.get_text().strip()\n",
    "                if spread_text == '' or spread_text == 'XXXX':\n",
    "                    away_spread = np.nan\n",
    "                    home_spread = np.nan\n",
    "                elif(spread_text[4] == '+' or spread_text[4] == '-'):\n",
    "                    away_spread = spread_text[0:4]\n",
    "                    home_spread = spread_text[4:]\n",
    "                else:\n",
    "                    away_spread = spread_text[0:5]\n",
    "                    home_spread = spread_text[5:]\n",
    "\n",
    "                temp_away_list.append(away_spread)\n",
    "                temp_home_list.append(home_spread)\n",
    "                \n",
    "                if len(temp_home_list) == 9:\n",
    "                    book = book.append(pd.Series(temp_away_list, index=names), ignore_index=True)\n",
    "                    book = book.append(pd.Series(temp_home_list, index=names), ignore_index=True)\n",
    "                    temp_away_list = []\n",
    "                    temp_home_list = []\n",
    "                    \n",
    "    book['team'] = teams_list\n",
    "    book['date'] = dates_list\n",
    "    book = book[book.date <= df.date.max()]    # Only getting odds for games in current week\n",
    "    odds = book[['team', 'odds']]\n",
    "    df = pd.merge(odds, df)[['week', 'date', 'team', '538 win%', 'Fox win%', 'odds']]\n",
    "\n",
    "    return df\n",
    "def date_formatter(row):\n",
    "    \"\"\"Loads odds to spreadsheet\n",
    "    Args:\n",
    "        df: dataframe that odds will be written to\n",
    "        year: year that will be used to gather the dates of the games\n",
    "    Returns:\n",
    "        dataframe of datawith odds\n",
    "    \"\"\"\n",
    "    \n",
    "    if row.date == '':\n",
    "        return(row.date)\n",
    "    else:\n",
    "        split_date = row.date.split('/')\n",
    "        day = split_date[1]\n",
    "        day = day.zfill(2)\n",
    "        date = split_date[0] + day + split_date[2]\n",
    "        date = datetime.datetime.strptime(date, '%m%d%Y')\n",
    "        date = date.strftime('%m/%d/%Y')\n",
    "        return(date)\n",
    "def date_ffill_formatter(df):\n",
    "    \"\"\"Loads odds to spreadsheet\n",
    "    Args:\n",
    "        df: df of data\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        if index%2 == 0:\n",
    "            continue\n",
    "        else:\n",
    "            df.at[index, 'date'] = ''            \n",
    "    \n",
    "def combining_data(df_top, df_bottom):\n",
    "    \"\"\"Appends two dataframes\n",
    "    Args:\n",
    "        df_top: dataframe of data to go on top\n",
    "        df_bottom: dataframe of data to go on bottom\n",
    "    Returns:\n",
    "        df: combined dataframe\n",
    "    \"\"\"\n",
    "    cols = df_top.columns\n",
    "    df = pd.concat([df_top, df_bottom], ignore_index=True, )\n",
    "    df = df[cols]\n",
    "    df.replace(np.nan, '', inplace=True)\n",
    "    return(df)\n",
    "def game_outcomes(game_date, team_name):\n",
    "    \"\"\"Finds winners and losers of games\n",
    "    Args:\n",
    "        game_date: date of game\n",
    "        team_name: city of team\n",
    "    Returns:\n",
    "        'w' for win or 'l' for loss\n",
    "    \"\"\"\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://projects.fivethirtyeight.com/2019-nfl-predictions/games/?ex_cid=rrpromo'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "    winners = []\n",
    "    losers = []\n",
    "\n",
    "    # Finding year of predictions\n",
    "    for timestamp in soup.findAll('div', attrs={'class': 'container'}):\n",
    "        for year in timestamp.findAll('div', attrs={'id': 'intro'}):\n",
    "            year = int(year.h1.get_text()[0:5])\n",
    "\n",
    "    # Gathering data\n",
    "    for week in soup.findAll('section', attrs={'class': 'week'}):\n",
    "        for week_text in week.findAll('h3', attrs={'class': 'h3'}):\n",
    "            week_num_text = week_text.get_text()[5:]\n",
    "            \n",
    "        \n",
    "        for date in week.findAll('div', attrs={'class': 'days'}):\n",
    "            for day in date.findAll('div', attrs={'class': 'day'}):  \n",
    "\n",
    "                # Finding date of each game  \n",
    "                for h4 in day.findAll('h4', attrs={'class': 'h4'}):\n",
    "                    date = h4.get_text()\n",
    "                    date = date.split(', ')[1]\n",
    "                    date = date[0:3] + ' ' + date[-2:].strip() + ' ' + str(year)\n",
    "                    date = datetime.datetime.strptime(date, '%b %d %Y')\n",
    "                    date = date.strftime('%m/%d/%Y')\n",
    "\n",
    "                    if date == game_date:\n",
    "                        # Finding data for each game\n",
    "                        for game_body in day.findAll('table', attrs={'class': 'game-body'}):\n",
    "                            for winner_tag in game_body.findAll('td', attrs={'class': 'td text team winner'}):\n",
    "                                winner = winner_tag.get_text().strip()\n",
    "                               \n",
    "                                if team_name == winner:\n",
    "                                    return('w')\n",
    "                                \n",
    "                            for loser_tag in game_body.findAll('td', attrs={'class': 'td text team loser'}):\n",
    "                                loser = loser_tag.get_text().strip()\n",
    "\n",
    "                                if team_name == loser:\n",
    "                                    return('l')\n",
    "        \n",
    "    return('')\n",
    "def odds_checker(row):\n",
    "    \"\"\"Checks if odds for game are present\n",
    "    Args:\n",
    "        row: row of data\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    if row['odds'] != '':\n",
    "        return(row['odds'])\n",
    "    else:\n",
    "        return(row['odds new'])  \n",
    "def implied_probability(row):\n",
    "    \"\"\"Uses odds to determine implied probability\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        implied win probability if it exists\n",
    "    \"\"\"\n",
    "    if 'implied' in row.index:\n",
    "        return row['implied']\n",
    "    elif row['odds'] == '':\n",
    "        return('')\n",
    "    elif row['odds'][0] == '+':\n",
    "        return(round(100.0/(100+int(row['odds'][1:])), 2))\n",
    "    elif row['odds'][0] == '-':\n",
    "        return(round(int(row['odds'][1:])/(100.0+int(row['odds'][1:])), 2))\n",
    "    else:\n",
    "        return('')    \n",
    "    \n",
    "    \n",
    "def pick(row, predictor):\n",
    "    \"\"\"Uses win% and odds to determine what team to pick\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "        predictor: name of predicting column\n",
    "    Returns:\n",
    "        pick if there is one\n",
    "    \"\"\"\n",
    "    if predictor + ' pick' in row.index:\n",
    "        if row[predictor + ' pick'] == '':\n",
    "            return ''\n",
    "        else:    \n",
    "            return(town_to_acronym_dict[row[predictor + ' pick']])\n",
    "    elif row['implied'] == '':\n",
    "        return('')\n",
    "    elif (float(row[predictor + ' win%'][:-1])/100.0 > row['implied']):\n",
    "        return(town_to_acronym_dict[row.team])\n",
    "    else:\n",
    "        return('')\n",
    "    \n",
    "def spreadsheet_formatter(df):\n",
    "    \"\"\"Formats spreadsheet\n",
    "    Args:\n",
    "        df: dataframe of data\n",
    "\n",
    "    \"\"\"\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "        \n",
    "    df.replace(np.nan, '', inplace=True)\n",
    "    \n",
    "    \n",
    "def odds_formatter(row):\n",
    "    \"\"\"Formats odds\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        formatted odds\n",
    "    \"\"\"\n",
    "    if row['odds'] == '':\n",
    "        return(row['odds'])\n",
    "    elif int(row['odds']) >= 100:\n",
    "        return('+' + str(row['odds']))\n",
    "    if int(row['odds']) <= -100:\n",
    "        return(str(row['odds']))\n",
    "    else:\n",
    "        return(str(row['odds'])) \n",
    "    \n",
    "def team_won_lost(row):\n",
    "    \"\"\"Determines team outcomes\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        updated entry for winner/loser\n",
    "    \"\"\"\n",
    "    game_date = row.date\n",
    "    team_name = row.team \n",
    "    result = game_outcomes(game_date, team_name)\n",
    "    if datetime.date.today().strftime('%m/%d/%Y') < row.date:\n",
    "        return('')\n",
    "    else:\n",
    "        if row.date != '':\n",
    "            if result == 'w':\n",
    "                return('w')\n",
    "            elif result == 'l':\n",
    "                return('l')\n",
    "            else:\n",
    "                return('')\n",
    "def money_won_lost(row, predictor):\n",
    "    \"\"\"Determines amount won lost\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "        predictor: name of predictor\n",
    "    Returns:\n",
    "        amount won/lost\n",
    "    \"\"\"\n",
    "    if row[predictor + ' pick'] == '':\n",
    "        return(int(0))\n",
    "    else:\n",
    "        if row['result'] == 'w':\n",
    "            if row['odds'][0] == '+':\n",
    "                return(int(row['odds'][1:]))\n",
    "            else:\n",
    "                return(100)\n",
    "        elif row['result'] == 'l':\n",
    "            if row['odds'][0] == '+':\n",
    "                return(-100)\n",
    "            else:\n",
    "                return(int(row['odds']))\n",
    "        else:\n",
    "            return(int(0))\n",
    "def week_finder(date):\n",
    "    \"\"\"Finds what week games are in\n",
    "    Args:\n",
    "        date: date in mm/dd/yyyy form\n",
    "    Returns:\n",
    "        week: week of games\n",
    "    \"\"\"\n",
    "    if date < datetime.date(2019, 9, 10):\n",
    "        week = 1\n",
    "    elif date < datetime.date(2019, 9, 17):\n",
    "        week = 2\n",
    "    elif date < datetime.date(2019, 9, 24):\n",
    "        week = 3\n",
    "    elif date < datetime.date(2019, 10, 1):\n",
    "        week = 4\n",
    "    elif date < datetime.date(2019, 10, 8):\n",
    "        week = 5\n",
    "    elif date < datetime.date(2019, 10, 15):\n",
    "        week = 6\n",
    "    elif date < datetime.date(2019, 10, 22):\n",
    "        week = 7\n",
    "    elif date < datetime.date(2019, 10, 29):\n",
    "        week = 8\n",
    "    elif date < datetime.date(2019, 11, 5):\n",
    "        week = 9\n",
    "    elif date < datetime.date(2019, 11, 12):\n",
    "        week = 10\n",
    "    elif date < datetime.date(2019, 11, 19):\n",
    "        week = 11\n",
    "    elif date < datetime.date(2019, 11, 26):\n",
    "        week = 12\n",
    "    elif date < datetime.date(2019, 12, 3):\n",
    "        week = 13\n",
    "    elif date < datetime.date(2019, 12, 10):\n",
    "        week = 14\n",
    "    elif date < datetime.date(2019, 12, 17):\n",
    "        week = 15\n",
    "    elif date < datetime.date(2019, 12, 24):\n",
    "        week = 16\n",
    "    elif date < datetime.date(2019, 12, 31):\n",
    "        week = 17\n",
    "    else:\n",
    "        week = 0\n",
    "        \n",
    "    return(week)\n",
    "def writing_spreadsheet(df, filename):\n",
    "    \"\"\"Writing to spreadsheet\n",
    "    Args:\n",
    "        df: data\n",
    "        file_name: path of file\n",
    "    \"\"\"\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name = 'z:\\\\python projects\\\\NFL Game Outcome Spreadsheet.csv'\n",
    "\n",
    "df = getting_spreadsheet(file_name) # Retrieving Spreadsheet\n",
    "spreadsheet_formatter(df)\n",
    "old_games, current_games = separating_games(df)\n",
    "\n",
    "if not current_games.empty:\n",
    "    current_games['date'] = current_games['date'].replace('', np.nan).ffill()\n",
    "    current_games['odds'] = current_games.apply(lambda row: odds_formatter(row), axis=1)\n",
    "    current_games['result'] = current_games.apply(lambda row: team_won_lost(row), axis=1)\n",
    "    current_games['538 w/l'] = current_games.apply(lambda row: money_won_lost(row, '538'), axis=1)\n",
    "    current_games['Fox w/l'] = current_games.apply(lambda row: money_won_lost(row, 'Fox'), axis=1)\n",
    "    df = combining_data(old_games, current_games)\n",
    "  \n",
    "df['date'] = df.apply(lambda row: date_formatter(row), axis=1)\n",
    "\n",
    "if datetime.date.today().strftime('%m/%d/%Y') > df.date.max():\n",
    "    new_games, year = predictions_538(week_num=week_finder(datetime.date.today()))\n",
    "    new_games = predictions_fox(new_games)\n",
    "    new_games = loading_odds(new_games, year)\n",
    "    new_games['implied'] = new_games.apply(lambda row: implied_probability(row), axis=1)\n",
    "    new_games['538 pick'] = new_games.apply(lambda row: pick(row, '538'), axis=1)\n",
    "    new_games['Fox pick'] = new_games.apply(lambda row: pick(row, 'Fox'), axis=1)\n",
    "    new_games['538 w/l'] = 0\n",
    "    new_games['Fox w/l'] = 0\n",
    "    df = combining_data(df, new_games)\n",
    "\n",
    "df['538 w/l'] = df['538 w/l'].astype(int)\n",
    "df['Fox w/l'] = df['Fox w/l'].astype(int)\n",
    "df['538 total'] = int(df.loc[df['538 w/l'] != np.nan]['538 w/l'].sum())\n",
    "df['Fox total'] = int(df.loc[df['Fox w/l'] != np.nan]['Fox w/l'].sum())\n",
    "date_ffill_formatter(df)\n",
    "df\n",
    "writing_spreadsheet(df, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
