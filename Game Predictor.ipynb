{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "code_folding": [
     7,
     39
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "header_name = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'\n",
    "team_acronym_dict = {'ARI': 'Arizona',\n",
    "                    'ATL': 'Atlanta',\n",
    "                    'BAL': 'Baltimore',\n",
    "                    'BUF': 'Buffalo',\n",
    "                    'CAR': 'Carolina',\n",
    "                    'CHI': 'Chicago',\n",
    "                    'CIN': 'Cincinnati',\n",
    "                    'CLE': 'Cleveland',\n",
    "                    'DAL': 'Dallas',\n",
    "                    'DEN': 'Denver',\n",
    "                    'DET': 'Detroit',\n",
    "                    'GB': 'Green Bay',\n",
    "                    'HOU': 'Houston',\n",
    "                    'IND': 'Indianapolis',\n",
    "                    'JAX': 'Jacksonville',\n",
    "                    'KC': 'Kansas City',\n",
    "                    'LAC': 'L.A. Chargers',\n",
    "                    'LAR': 'L.A. Rams',\n",
    "                    'MIA': 'Miami',\n",
    "                    'MIN': 'Minnesota',\n",
    "                    'NE': 'New England',\n",
    "                    'NO': 'New Orleans',\n",
    "                    'NYG': 'N.Y. Giants',\n",
    "                    'NYJ': 'N.Y. Jets',\n",
    "                    'OAK': 'Oakland',\n",
    "                    'PHI': 'Philadelphia',\n",
    "                    'PIT': 'Pittsburgh',\n",
    "                    'SEA': 'Seattle',\n",
    "                    'SF': 'San Francisco',\n",
    "                    'TB': 'Tampa Bay',\n",
    "                    'TEN': 'Tennessee',\n",
    "                    'WAS': 'Washington'}\n",
    "nickname_town_dict = {'Cardinals': 'Arizona',\n",
    "                    'Falcons': 'Atlanta',\n",
    "                    'Ravens': 'Baltimore',\n",
    "                    'Bills': 'Buffalo',\n",
    "                    'Panthers': 'Carolina',\n",
    "                    'Bears': 'Chicago',\n",
    "                    'Bengals': 'Cincinnati',\n",
    "                    'Browns': 'Cleveland',\n",
    "                    'Cowboys': 'Dallas',\n",
    "                    'Broncos': 'Denver',\n",
    "                    'Lions': 'Detroit',\n",
    "                    'Packers': 'Green Bay',\n",
    "                    'Texans': 'Houston',\n",
    "                    'Colts': 'Indianapolis',\n",
    "                    'Jaguars': 'Jacksonville',\n",
    "                    'Chiefs': 'Kansas City',\n",
    "                    'Chargers': 'L.A. Chargers',\n",
    "                    'Rams': 'L.A. Rams',\n",
    "                    'Dolphins': 'Miami',\n",
    "                    'Vikings': 'Minnesota',\n",
    "                    'Patriots': 'New England',\n",
    "                    'Saints': 'New Orleans',\n",
    "                    'Giants': 'N.Y. Giants',\n",
    "                    'Jets': 'N.Y. Jets',\n",
    "                    'Raiders': 'Oakland',\n",
    "                    'Eagles': 'Philadelphia',\n",
    "                    'Steelers': 'Pittsburgh',\n",
    "                    'Seahawks': 'Seattle',\n",
    "                    '49ers': 'San Francisco',\n",
    "                    'Buccaneers': 'Tampa Bay',\n",
    "                    'Titans': 'Tennessee',\n",
    "                    'Redskins': 'Washington'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "code_folding": [
     0,
     63,
     71,
     83,
     208,
     279,
     300,
     313,
     366,
     377,
     396,
     412,
     423,
     439,
     453,
     475,
     520,
     528
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initial_538_predictions(week_num):\n",
    "    \"\"\"Creates dataframe with initial values from 538\n",
    "    Args:\n",
    "        week_num: week number of games\n",
    "    Returns:\n",
    "        dataframe of 538 predictions\n",
    "    \"\"\"\n",
    "    df_columns = ['week', 'date', 'team', '538 win%']\n",
    "    df = pd.DataFrame(columns=df_columns)\n",
    "    \n",
    "    output_file = 'z:\\python_projects\\aaa.exe'\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://projects.fivethirtyeight.com/2019-nfl-predictions/games/?ex_cid=rrpromo'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "    # Finding year of predictions\n",
    "    for timestamp in soup.findAll('div', attrs={'class': 'container'}):\n",
    "        for year in timestamp.findAll('div', attrs={'id': 'intro'}):\n",
    "            year = int(year.h1.get_text()[0:5])\n",
    "\n",
    "    # Gathering data\n",
    "    for week in soup.findAll('section', attrs={'class': 'week'}):\n",
    "        if week.get_text()[5] == str(week_num):\n",
    "            for date in week.findAll('div', attrs={'class': 'days'}):\n",
    "                for weekday in date.findAll('div', attrs={'class': 'day'}):  \n",
    "                    for game in weekday.findAll('div', attrs={'class': 'game'}):\n",
    "\n",
    "                        # Finding date of each game  \n",
    "                        for h4 in weekday.findAll('h4', attrs={'class': 'h4'}):\n",
    "                            date = h4.get_text().strip()\n",
    "                            date = date.split(', ')[1]\n",
    "                            date = date[0:3] + date[4:] + ' ' + str(year)\n",
    "                            date = datetime.datetime.strptime(date, '%b %d %Y')\n",
    "                            year = date.year\n",
    "                            month = date.month\n",
    "                            day = date.day\n",
    "                            date = date.strftime('%m/%d/%Y')\n",
    "\n",
    "                        # Finding data for each game\n",
    "                        for game_body in game.findAll('table', attrs={'class': 'game-body'}):           \n",
    "                            for num_teams, matchup in enumerate(game_body.findAll('tr', attrs={'class': 'tr'})):\n",
    "                                squad = matchup.find('td', attrs={'class': 'td text team'})\n",
    "                                win_percentage = matchup.find('td', attrs={'class': 'td number chance'}).get_text().strip()\n",
    "\n",
    "                                if squad:\n",
    "                                    team = squad.get_text().strip()\n",
    "                                    result = ''\n",
    "                                    \n",
    "                                    if num_teams == 0:\n",
    "                                        df = df.append(pd.Series([week_finder(datetime.date(year, month, day)),\n",
    "                                                                  date, team, win_percentage], index=df.columns),\n",
    "                                                                  ignore_index=True)\n",
    "                                    else:\n",
    "                                        df = df.append(pd.Series([week_finder(datetime.date(year, month, day)),\n",
    "                                                                  '', team, win_percentage], index=df.columns),\n",
    "                                                                  ignore_index=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df, year\n",
    "    \n",
    "def getting_spreadsheet(file_name):\n",
    "    \"\"\"Loads spreadsheet\n",
    "    Args:\n",
    "        file_name: path of file\n",
    "    Returns:\n",
    "        dataframe of data\n",
    "    \"\"\"\n",
    "    return(pd.read_csv(file_name))\n",
    "def separating_games(df):\n",
    "    \"\"\"Separates old games and new games\n",
    "    Args:\n",
    "        df: dataframe of data\n",
    "    Returns:\n",
    "        old_games: games with results already\n",
    "        current_game: games without results\n",
    "    \"\"\"\n",
    "    old_games = df[df['result'] != '']\n",
    "    old_games_index = df[df['result'] != ''].index \n",
    "    current_games = df.drop(old_games_index)\n",
    "    return old_games, current_games\n",
    "def predictions_538(week_num):\n",
    "    \"\"\"Loads 538 predictions\n",
    "    Args:\n",
    "        week_num: week number of games\n",
    "    Returns:\n",
    "        df: dataframe with 538 predictions\n",
    "        year: year of games. Needed for Vegas odds\n",
    "    \"\"\"\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://projects.fivethirtyeight.com/2019-nfl-predictions/games/?ex_cid=rrpromo'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "    cols = ['week', 'date', 'team', '538 win%']\n",
    "    blank_rows = ['']*(len(df.columns)-3)\n",
    "    cols.extend(blank_rows)\n",
    "    predictions = pd.DataFrame(columns=cols)\n",
    "\n",
    "    # Finding year of predictions\n",
    "    for timestamp in soup.findAll('div', attrs={'class': 'container'}):\n",
    "        for year in timestamp.findAll('div', attrs={'id': 'intro'}):\n",
    "            year = int(year.h1.get_text()[0:5])\n",
    "\n",
    "    # Gathering data\n",
    "    for week in soup.findAll('section', attrs={'class': 'week'}):\n",
    "        if week.get_text()[5] == str(week_num):\n",
    "            for date in week.findAll('div', attrs={'class': 'days'}):\n",
    "                for weekday in date.findAll('div', attrs={'class': 'day'}):  \n",
    "                    for game in weekday.findAll('div', attrs={'class': 'game'}):\n",
    "\n",
    "                        # Finding date of each game  \n",
    "                        for h4 in weekday.findAll('h4', attrs={'class': 'h4'}):\n",
    "                            date = h4.get_text().strip()\n",
    "                            date = date.split(', ')[1]\n",
    "                            date = date[0:3] + date[4:] + ' ' + str(year)\n",
    "                            date = datetime.datetime.strptime(date, '%b %d %Y')\n",
    "                            year = date.year\n",
    "                            month = date.month\n",
    "                            day = date.day\n",
    "                            date = date.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "                        # Finding data for each game\n",
    "                        for game_body in game.findAll('table', attrs={'class': 'game-body'}):           \n",
    "                            for num_teams, matchup in enumerate(game_body.findAll('tr', attrs={'class': 'tr'})):\n",
    "                                squad = matchup.find('td', attrs={'class': 'td text team'})\n",
    "                                win_percentage = matchup.find('td', attrs={'class': 'td number chance'}).get_text().strip()\n",
    "\n",
    "                                if squad:\n",
    "                                    team = squad.get_text().strip()\n",
    "                                    result = ''\n",
    "                                    \n",
    "                                    if num_teams == 0:\n",
    "                                        row_data = [week_finder(datetime.date(year, month, day)), date, team, win_percentage]\n",
    "                                        row_data.extend(blank_rows)\n",
    "                                        \n",
    "                                        predictions = predictions.append(pd.Series(row_data, index=predictions.columns), \n",
    "                                                                         ignore_index=True)\n",
    "                                    else:\n",
    "                                        row_data = [week_finder(datetime.date(year, month, day)), '', team, win_percentage]\n",
    "                                        row_data.extend(blank_rows)\n",
    "\n",
    "                                        predictions = predictions.append(pd.Series(row_data, index=predictions.columns), \n",
    "                                                                         ignore_index=True)\n",
    "  \n",
    "    return predictions, year\n",
    "def predictions_fox(df):\n",
    "    \"\"\"Loads fox predictions\n",
    "    Args:\n",
    "    df: dataframe of data that will be merged with\n",
    "    Returns:\n",
    "        df: dataframe including Fox predictions\n",
    "    \"\"\"\n",
    "    predictions_columns = ['week', 'team', 'Fox win%']\n",
    "    predictions = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://www.foxsports.com/nfl/predictions'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "    for week in soup.findAll('option', attrs={'selected': 'selected'}):\n",
    "        week_num = week.get_text().strip()[5:]\n",
    "        print(week_num)\n",
    "\n",
    "\n",
    "    for matchup in soup.findAll('div', attrs={'class': 'wisbb_predictionChip'}):\n",
    "        for num, team_name in enumerate(matchup.findAll('span', attrs={'class': 'wisbb_teamName'})):\n",
    "            if num == 0:\n",
    "                away_team = team_name.get_text().strip()\n",
    "            elif num == 1:\n",
    "                home_team = team_name.get_text().strip()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        for num, fox_predictions in enumerate(matchup.findAll('span', attrs={'class': 'wisbb_predData'})):\n",
    "            prediction_text = fox_predictions.get_text()\n",
    "            team_acronym = fox_predictions.get_text()[0:3].strip()\n",
    "            if team_acronym in team_acronym_dict and len(prediction_text)>4 and num ==1:\n",
    "                if team_acronym_dict[team_acronym] == nickname_town_dict[away_team]:\n",
    "                    away_win_percentage_int = int(round(float(prediction_text.split('(')[1][:-2])))\n",
    "                    away_win_percentage_string = str(away_win_percentage_int) + '%'\n",
    "                    home_win_percentage_int = 100 - away_win_percentage_int\n",
    "                    home_win_percentage_string = str(home_win_percentage_int) + '%'\n",
    "\n",
    "                elif team_acronym_dict[team_acronym] == nickname_town_dict[home_team]:\n",
    "                    home_win_percentage_int = int(round(float(prediction_text.split('(')[1][:-2])))\n",
    "                    home_win_percentage_string = str(home_win_percentage_int) + '%'\n",
    "                    away_win_percentage_int = 100 - home_win_percentage_int\n",
    "                    away_win_percentage_string = str(away_win_percentage_int) + '%'\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                predictions = predictions.append(pd.Series([week_num, nickname_town_dict[away_team], away_win_percentage_string],\n",
    "                                             index=predictions.columns), ignore_index=True)\n",
    "                predictions = predictions.append(pd.Series([week_num, nickname_town_dict[home_team], home_win_percentage_string],\n",
    "                                             index=predictions.columns), ignore_index=True)\n",
    "    print(predictions.iloc[0]['week'] == df.iloc[0]['week'])\n",
    "    print(df.iloc[0]['week'])\n",
    "\n",
    "    df = pd.merge(predictions, df)\n",
    "    print(df)\n",
    "    return df\n",
    "def loading_odds(df, year):\n",
    "    \"\"\"Loads odds to spreadsheet\n",
    "    Args:\n",
    "        df: dataframe that odds will be written to\n",
    "        year: year that will be used to gather the dates of the games\n",
    "    Returns:\n",
    "        dataframe of datawith odds\n",
    "    \"\"\"\n",
    "    names = ['Open', 'odds','Westgate','MGM Mirage', 'betMGM',\n",
    "             'William Hill', 'CG Technology', 'Circa Sports','Stations']\n",
    "    book = pd.DataFrame(columns=names)\n",
    "    output_file = 'z:\\python_projects\\aaa.exe'\n",
    "    temp_away_list = []\n",
    "    temp_home_list = []\n",
    "    teams_list = []\n",
    "    dates_list = []\n",
    "    URL = 'http://www.vegasinsider.com/nfl/odds/las-vegas/money/'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "    for gameboard in soup.findAll('table', attrs={'class': 'viBodyContainerTble'}):\n",
    "        for num, games in enumerate(gameboard.findAll('td', attrs={'class': 'viBodyBorderNorm'})):\n",
    "            for game_info in games.findAll('td'):  \n",
    "                for date in game_info.findAll('span', attrs={'class': 'cellTextHot'}):\n",
    "                    date = date.get_text().split()[0]\n",
    "                    month = date.split('/')[0]\n",
    "                    day = date.split('/')[1]\n",
    "\n",
    "                    if(int(day[0]) == 0):\n",
    "                        day = day[1:]\n",
    "\n",
    "                    date = str(month) + '/' + str(day) + '/' + str(year)\n",
    "                    dates_list.extend([date, date])\n",
    "\n",
    "                for team_name in game_info.findAll('a', attrs={'class': 'tabletext'}):\n",
    "                    teams_list.append(team_name.get_text())\n",
    "\n",
    "            for num, spread in enumerate(games.findAll('td',attrs={'class': \n",
    "                                                                  ['viCellBg1 cellTextNorm cellBorderL1 center_text nowrap',\n",
    "                                                                   'viCellBg1 cellTextHot cellBorderL1 center_text nowrap',\n",
    "                                                                   'viCellBg2 cellTextNorm cellBorderL1 center_text nowrap',\n",
    "                                                                   'viCellBg2 cellTextHot cellBorderL1 center_text nowrap']})):           \n",
    "                spread_text = spread.get_text().strip()\n",
    "                if spread_text == '' or spread_text == 'XXXX':\n",
    "                    away_spread = np.nan\n",
    "                    home_spread = np.nan\n",
    "                elif(spread_text[4] == '+' or spread_text[4] == '-'):\n",
    "                    away_spread = spread_text[0:4]\n",
    "                    home_spread = spread_text[4:]\n",
    "                else:\n",
    "                    away_spread = spread_text[0:5]\n",
    "                    home_spread = spread_text[5:]\n",
    "\n",
    "                temp_away_list.append(away_spread)\n",
    "                temp_home_list.append(home_spread)\n",
    "                \n",
    "                if len(temp_home_list) == 9:\n",
    "                    book = book.append(pd.Series(temp_away_list, index=names), ignore_index=True)\n",
    "                    book = book.append(pd.Series(temp_home_list, index=names), ignore_index=True)\n",
    "                    temp_away_list = []\n",
    "                    temp_home_list = []\n",
    "\n",
    "    book['team'] = teams_list\n",
    "    book['date'] = dates_list\n",
    "\n",
    "    book = book[book.date <= df.date.max()]    # Only getting odds for games in current week\n",
    "    odds = book[['team', 'odds']]\n",
    "    df = pd.merge(odds, df)[['week', 'date', 'team', 'win%', 'odds']]\n",
    "\n",
    "    return df\n",
    "def date_formatter(row):\n",
    "    \"\"\"Loads odds to spreadsheet\n",
    "    Args:\n",
    "        df: dataframe that odds will be written to\n",
    "        year: year that will be used to gather the dates of the games\n",
    "    Returns:\n",
    "        dataframe of datawith odds\n",
    "    \"\"\"\n",
    "    \n",
    "    if row.date == '':\n",
    "        return(row.date)\n",
    "    else:\n",
    "        split_date = row.date.split('/')\n",
    "        day = split_date[1]\n",
    "        day = day.zfill(2)\n",
    "        date = split_date[0] + day + split_date[2]\n",
    "        date = datetime.datetime.strptime(date, '%m%d%Y')\n",
    "        date = date.strftime('%m/%d/%Y')\n",
    "        return(date)\n",
    "            \n",
    "    \n",
    "def combining_data(df_top, df_bottom):\n",
    "    \"\"\"Appends two dataframes\n",
    "    Args:\n",
    "        df_top: dataframe of data to go on top\n",
    "        df_bottom: dataframe of data to go on bottom\n",
    "    Returns:\n",
    "        df: combined dataframe\n",
    "    \"\"\"\n",
    "    cols = df_top.columns\n",
    "    df = pd.concat([df_top, df_bottom], ignore_index=True, )\n",
    "    df = df[cols]\n",
    "    df.replace(np.nan, '', inplace=True)\n",
    "    return(df)\n",
    "def game_outcomes(df, week_num):\n",
    "    \"\"\"Finds winners and losers of games\n",
    "    Args:\n",
    "        df: dataframe of data\n",
    "        week_num: week of games\n",
    "    Returns:\n",
    "        winners, losers: lists of winners and loser of games\n",
    "    \"\"\"\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://projects.fivethirtyeight.com/2019-nfl-predictions/games/?ex_cid=rrpromo'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "    winners = []\n",
    "    losers = []\n",
    "\n",
    "    # Finding year of predictions\n",
    "    for timestamp in soup.findAll('div', attrs={'class': 'container'}):\n",
    "        for year in timestamp.findAll('div', attrs={'id': 'intro'}):\n",
    "            year = int(year.h1.get_text()[0:5])\n",
    "\n",
    "    # Gathering data\n",
    "    for week in soup.findAll('section', attrs={'class': 'week'}):\n",
    "        if week.get_text()[5] == str(week_num):\n",
    "            for date in week.findAll('div', attrs={'class': 'days'}):\n",
    "                for day in date.findAll('div', attrs={'class': 'day'}):  \n",
    "                    for game in day.findAll('div', attrs={'class': 'game'}):\n",
    "\n",
    "                        # Finding date of each game  \n",
    "                        for h4 in day.findAll('h4', attrs={'class': 'h4'}):\n",
    "                            date = h4.get_text()\n",
    "                            date = date.split(', ')[1]\n",
    "                            date = date[0:3] + date[4:6] + ' ' + str(year)\n",
    "                            date = datetime.datetime.strptime(date, '%b %d %Y')\n",
    "                            date = date.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "                        # Finding data for each game\n",
    "                        for game_body in game.findAll('table', attrs={'class': 'game-body'}):           \n",
    "                            for num_teams, matchup in enumerate(game_body.findAll('tr', attrs={'class': 'tr'})):\n",
    "                                winner = matchup.find('td', attrs={'class': 'td text team winner'})\n",
    "                                loser = matchup.find('td', attrs={'class': 'td text team loser'})\n",
    "\n",
    "                                if winner:\n",
    "                                    winners.append(winner.get_text().strip())\n",
    "                                elif loser:\n",
    "                                    losers.append(loser.get_text().strip())\n",
    "                                else:\n",
    "                                    continue\n",
    "                                \n",
    "    \n",
    "    return winners, losers\n",
    "def odds_checker(row):\n",
    "    \"\"\"Checks if odds for game are present\n",
    "    Args:\n",
    "        row: row of data\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    if row['odds'] != '':\n",
    "        return(row['odds'])\n",
    "    else:\n",
    "        return(row['odds new'])  \n",
    "def implied_probability(row):\n",
    "    \"\"\"Uses odds to determine implied probability\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        implied win probability if it exists\n",
    "    \"\"\"\n",
    "    if 'implied' in row.index:\n",
    "        return row['implied']\n",
    "    elif row['odds'] == '':\n",
    "        return('')\n",
    "    elif row['odds'][0] == '+':\n",
    "        return(round(100.0/(100+int(row['odds'][1:])), 2))\n",
    "    elif row['odds'][0] == '-':\n",
    "        return(round(int(row['odds'][1:])/(100.0+int(row['odds'][1:])), 2))\n",
    "    else:\n",
    "        return('')    \n",
    "    \n",
    "    \n",
    "def pick(row):\n",
    "    \"\"\"Uses win% and odds to determine what team to pick\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        pick if there is one\n",
    "    \"\"\"\n",
    "    if 'pick' in row.index:\n",
    "        return(row['pick'])\n",
    "    elif row['implied'] == '':\n",
    "        return('')\n",
    "    elif (float(row['win%'][:-1])/100.0 > row['implied']):\n",
    "        return(row.team)\n",
    "    else:\n",
    "        return('')\n",
    "    \n",
    "def spreadsheet_formatter(df):\n",
    "    \"\"\"Formats spreadsheet\n",
    "    Args:\n",
    "        df: dataframe of data\n",
    "\n",
    "    \"\"\"\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "        \n",
    "    df.replace(np.nan, '', inplace=True)\n",
    "    \n",
    "def odds_formatter(row):\n",
    "    \"\"\"Formats odds\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        formatted odds\n",
    "    \"\"\"\n",
    "    if row['odds'] == '':\n",
    "        return(row['odds'])\n",
    "    elif int(row['odds']) >= 100:\n",
    "        return('+' + str(row['odds']))\n",
    "    if int(row['odds']) <= -100:\n",
    "        return(str(row['odds']))\n",
    "    else:\n",
    "        return(str(row['odds'])) \n",
    "    \n",
    "def team_won_lost(row, winners, losers):\n",
    "    \"\"\"Determines team outcomes\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        updated entry for winner/loser\n",
    "    \"\"\"\n",
    "    if row['team'] in winners:\n",
    "        return('w')\n",
    "    elif row['team'] in losers:\n",
    "        return('l')\n",
    "    else:\n",
    "        return('')\n",
    "     \n",
    "def money_won_lost(row):\n",
    "    \"\"\"Determines amount won lost\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        amount won/lost\n",
    "    \"\"\"\n",
    "    if row['pick'] == '':\n",
    "        return(0)\n",
    "    else:\n",
    "        if row['result'] == 'w':\n",
    "            if row['odds'][0] == '+':\n",
    "                return(int(row['odds'][1:]))\n",
    "            else:\n",
    "                return(100)\n",
    "        elif row['result'] == 'l':\n",
    "            if row['odds'][0] == '+':\n",
    "                return(-100)\n",
    "            else:\n",
    "                return(int(row['odds']))\n",
    "        else:\n",
    "            return(0)\n",
    "def week_finder(date):\n",
    "    \"\"\"Finds what week games are in\n",
    "    Args:\n",
    "        date: date in mm/dd/yyyy form\n",
    "    Returns:\n",
    "        week: week of games\n",
    "    \"\"\"\n",
    "    if date < datetime.date(2019, 9, 10):\n",
    "        week = 1\n",
    "    elif date < datetime.date(2019, 9, 17):\n",
    "        week = 2\n",
    "    elif date < datetime.date(2019, 9, 24):\n",
    "        week = 3\n",
    "    elif date < datetime.date(2019, 10, 1):\n",
    "        week = 4\n",
    "    elif date < datetime.date(2019, 10, 8):\n",
    "        week = 5\n",
    "    elif date < datetime.date(2019, 10, 15):\n",
    "        week = 6\n",
    "    elif date < datetime.date(2019, 10, 22):\n",
    "        week = 7\n",
    "    elif date < datetime.date(2019, 10, 29):\n",
    "        week = 8\n",
    "    elif date < datetime.date(2019, 11, 5):\n",
    "        week = 9\n",
    "    elif date < datetime.date(2019, 11, 12):\n",
    "        week = 10\n",
    "    elif date < datetime.date(2019, 11, 19):\n",
    "        week = 11\n",
    "    elif date < datetime.date(2019, 11, 26):\n",
    "        week = 12\n",
    "    elif date < datetime.date(2019, 12, 3):\n",
    "        week = 13\n",
    "    elif date < datetime.date(2019, 12, 10):\n",
    "        week = 14\n",
    "    elif date < datetime.date(2019, 12, 17):\n",
    "        week = 15\n",
    "    elif date < datetime.date(2019, 12, 24):\n",
    "        week = 16\n",
    "    elif date < datetime.date(2019, 12, 31):\n",
    "        week = 17\n",
    "    else:\n",
    "        week = 0\n",
    "        \n",
    "    return(week)\n",
    "def team_acronym_converter(team_acronyms):\n",
    "    \"\"\"Converts acronym to team name\n",
    "    Args:\n",
    "        acronym: acronym of team\n",
    "    Returns:\n",
    "        name of team\n",
    "    \"\"\"\n",
    "    return team_acronym[acronym]\n",
    "def writing_spreadsheet(df, filename):\n",
    "    \"\"\"Writing to spreadsheet\n",
    "    Args:\n",
    "        df: data\n",
    "        file_name: path of file\n",
    "    \"\"\"\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7\n",
      "False\n",
      "7\n",
      "Empty DataFrame\n",
      "Columns: [week, team, Fox win%, date, 538 win%, , , , , , , ]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [week, team, Fox win%, date, 538 win%, , , , , , , ]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['win%'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-2070bf047895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mnew_games\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions_fox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_games\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_games\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mnew_games\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloading_odds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_games\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mnew_games\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'implied'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_games\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimplied_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mnew_games\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pick'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_games\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-178-499bfb7afdf3>\u001b[0m in \u001b[0;36mloading_odds\u001b[1;34m(df, year)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbook\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m# Only getting odds for games in current week\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[0modds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbook\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'team'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'odds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0modds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'week'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'team'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'win%'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'odds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2000\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2003\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s not in index'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['win%'] not in index\""
     ]
    }
   ],
   "source": [
    "file_name = 'z:\\\\python projects\\\\NFL Game Outcome Spreadsheet.csv'\n",
    "\n",
    "df = getting_spreadsheet(file_name) # Retrieving Spreadsheet\n",
    "spreadsheet_formatter(df)\n",
    "old_games, current_games = separating_games(df)\n",
    "current_games['odds'] = current_games.apply(lambda row: odds_formatter(row), axis=1)\n",
    "winners, losers = game_outcomes(current_games, week_num=week_finder(datetime.date.today())-1)\n",
    "\n",
    "current_games['result'] = current_games.apply(lambda row: team_won_lost(row, winners, losers), axis=1)\n",
    "\n",
    "current_games['w/l'] = current_games.apply(lambda row: money_won_lost(row), axis=1)\n",
    "current_games['total'] = current_games['w/l'].sum()\n",
    "df = combining_data(old_games, current_games)\n",
    "df['date'] = df.apply(lambda row: date_formatter(row), axis=1)\n",
    "\n",
    "if datetime.date.today().strftime('%m/%d/%Y') > df.date.max():\n",
    "    new_games, year = predictions_538(week_num=week_finder(datetime.date.today()))\n",
    "    new_games = predictions_fox(new_games)\n",
    "    print(new_games)\n",
    "    new_games = loading_odds(new_games, year)\n",
    "    new_games['implied'] = new_games.apply(lambda row: implied_probability(row), axis=1)\n",
    "    new_games['pick'] = new_games.apply(lambda row: pick(row), axis=1)\n",
    "    df = combining_data(df, new_games)\n",
    "\n",
    "df\n",
    "#writing_spreadsheet(df, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_columns = ['date', 'team', 'win%']\n",
    "df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "year = 2019\n",
    "result = ''\n",
    "URL = 'https://www.espn.com/nfl/scoreboard/_/year/2019/seasontype/2/week/6'\n",
    "#URL = 'https://www.espn.com/nfl/game/_/gameId/401128132'\n",
    "headers = {'User-Agent': header_name}\n",
    "source = requests.get(URL, headers=headers)\n",
    "soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "for a in soup.findAll('div', attrs={'class': 'scoreboard-top no-tabs'}):\n",
    "    print(a.get_text())\n",
    "\n",
    "for a in soup.findAll('a', attrs={'class': 'button-alt sm'}):\n",
    "    print(a)\n",
    "#for a in soup.findAll('body'):#, attrs={'class': 'mobileScoreboardLink'}):\n",
    "        #print(a.get_text())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>team</th>\n",
       "      <th>Fox win%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Denver</td>\n",
       "      <td>18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Green Bay</td>\n",
       "      <td>62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Miami</td>\n",
       "      <td>24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>L.A. Rams</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>Houston</td>\n",
       "      <td>47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>N.Y. Giants</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>Washington</td>\n",
       "      <td>8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>L.A. Chargers</td>\n",
       "      <td>64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>New England</td>\n",
       "      <td>66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>N.Y. Jets</td>\n",
       "      <td>34%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week           team Fox win%\n",
       "0     7    Kansas City      82%\n",
       "1     7         Denver      18%\n",
       "2     7        Oakland      38%\n",
       "3     7      Green Bay      62%\n",
       "4     7          Miami      24%\n",
       "5     7        Buffalo      76%\n",
       "6     7      L.A. Rams      75%\n",
       "7     7        Atlanta      25%\n",
       "8     7      Minnesota      46%\n",
       "9     7        Detroit      54%\n",
       "10    7        Houston      47%\n",
       "11    7   Indianapolis      53%\n",
       "12    7        Arizona      45%\n",
       "13    7    N.Y. Giants      55%\n",
       "14    7  San Francisco      92%\n",
       "15    7     Washington       8%\n",
       "16    7   Jacksonville      73%\n",
       "17    7     Cincinnati      27%\n",
       "18    7  L.A. Chargers      64%\n",
       "19    7      Tennessee      36%\n",
       "20    7    New Orleans      53%\n",
       "21    7        Chicago      47%\n",
       "22    7      Baltimore      39%\n",
       "23    7        Seattle      61%\n",
       "24    7   Philadelphia      48%\n",
       "25    7         Dallas      52%\n",
       "26    7    New England      66%\n",
       "27    7      N.Y. Jets      34%"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = ['week', 'team', 'Fox win%']\n",
    "df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "year = 2019\n",
    "result = ''\n",
    "URL = 'https://www.foxsports.com/nfl/predictions'\n",
    "headers = {'User-Agent': header_name}\n",
    "source = requests.get(URL, headers=headers)\n",
    "soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "for week in soup.findAll('option', attrs={'selected': 'selected'}):\n",
    "    week_num = week.get_text().strip()[5:]\n",
    "    \n",
    "    \n",
    "for matchup in soup.findAll('div', attrs={'class': 'wisbb_predictionChip'}):\n",
    "    for num, team_name in enumerate(matchup.findAll('span', attrs={'class': 'wisbb_teamName'})):\n",
    "        if num == 0:\n",
    "            away_team = team_name.get_text().strip()\n",
    "        elif num == 1:\n",
    "            home_team = team_name.get_text().strip()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    for num, predictions in enumerate(matchup.findAll('span', attrs={'class': 'wisbb_predData'})):\n",
    "        prediction_text = predictions.get_text()\n",
    "        team_acronym = predictions.get_text()[0:3].strip()\n",
    "        if team_acronym in team_acronym_dict and len(prediction_text)>4 and num ==1:\n",
    "            if team_acronym_dict[team_acronym] == nickname_town_dict[away_team]:\n",
    "                away_win_percentage_int = int(round(float(prediction_text.split('(')[1][:-2])))\n",
    "                away_win_percentage_string = str(away_win_percentage_int) + '%'\n",
    "                home_win_percentage_int = 100 - away_win_percentage_int\n",
    "                home_win_percentage_string = str(home_win_percentage_int) + '%'\n",
    "                \n",
    "            elif team_acronym_dict[team_acronym] == nickname_town_dict[home_team]:\n",
    "                home_win_percentage_int = int(round(float(prediction_text.split('(')[1][:-2])))\n",
    "                home_win_percentage_string = str(home_win_percentage_int) + '%'\n",
    "                away_win_percentage_int = 100 - home_win_percentage_int\n",
    "                away_win_percentage_string = str(away_win_percentage_int) + '%'\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            df = df.append(pd.Series([week_num, nickname_town_dict[away_team], away_win_percentage_string],\n",
    "                                         index=df.columns), ignore_index=True)\n",
    "            df = df.append(pd.Series([week_num, nickname_town_dict[home_team], home_win_percentage_string],\n",
    "                                         index=df.columns), ignore_index=True)\n",
    "            \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
