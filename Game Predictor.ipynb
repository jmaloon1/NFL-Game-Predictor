{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     7,
     38
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "header_name = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'\n",
    "team_acronym_dict = {'ATL': 'Atlanta',\n",
    "                    'BAL': 'Baltimore',\n",
    "                    'BUF': 'Buffalo',\n",
    "                    'CAR': 'Carolina',\n",
    "                    'CHI': 'Chicago',\n",
    "                    'CIN': 'Cincinnati',\n",
    "                    'CLE': 'Cleveland',\n",
    "                    'DAL': 'Dallas',\n",
    "                    'DEN': 'Denver',\n",
    "                    'DET': 'Detroit',\n",
    "                    'GB': 'Green Bay',\n",
    "                    'HOU': 'Houston',\n",
    "                    'IND': 'Indianapolis',\n",
    "                    'JAX': 'Jacksonville',\n",
    "                    'KC': 'Kansas City',\n",
    "                    'LAC': 'L.A. Chargers',\n",
    "                    'LAR': 'L.A. Rams',\n",
    "                    'MIA': 'Miami',\n",
    "                    'MIN': 'Minnesota',\n",
    "                    'NE': 'New England',\n",
    "                    'NO': 'New Orleans',\n",
    "                    'NYG': 'N.Y. Giants',\n",
    "                    'NYJ': 'N.Y. Jets',\n",
    "                    'OAK': 'Oakland',\n",
    "                    'PHI': 'Philadelphia',\n",
    "                    'PIT': 'Pittsburgh',\n",
    "                    'SEA': 'Seattle',\n",
    "                    'SF': 'San Francisco',\n",
    "                    'TB': 'Tampa Bay',\n",
    "                    'TEN': 'Tennessee',\n",
    "                    'WAS': 'Washington'}\n",
    "nickname_town_dict = {'Falcons': 'Atlanta',\n",
    "                    'Ravens': 'Baltimore',\n",
    "                    'Bills': 'Buffalo',\n",
    "                    'Panthers': 'Carolina',\n",
    "                    'Bears': 'Chicago',\n",
    "                    'Bengals': 'Cincinnati',\n",
    "                    'Browns': 'Cleveland',\n",
    "                    'Cowboys': 'Dallas',\n",
    "                    'Broncos': 'Denver',\n",
    "                    'Lions': 'Detroit',\n",
    "                    'Packers': 'Green Bay',\n",
    "                    'Texans': 'Houston',\n",
    "                    'Colts': 'Indianapolis',\n",
    "                    'Jaguars': 'Jacksonville',\n",
    "                    'Chiefs': 'Kansas City',\n",
    "                    'Chargers': 'L.A. Chargers',\n",
    "                    'Rams': 'L.A. Rams',\n",
    "                    'Dolphins': 'Miami',\n",
    "                    'Vikings': 'Minnesota',\n",
    "                    'Patriots': 'New England',\n",
    "                    'Saints': 'New Orleans',\n",
    "                    'Giants': 'N.Y. Giants',\n",
    "                    'Jets': 'N.Y. Jets',\n",
    "                    'Raiders': 'Oakland',\n",
    "                    'Eagles': 'Philadelphia',\n",
    "                    'Steelers': 'Pittsburgh',\n",
    "                    'Seahawks': 'Seattle',\n",
    "                    '49ers': 'San Francisco',\n",
    "                    'Buccaneers': 'Tampa Bay',\n",
    "                    'Titans': 'Tennessee',\n",
    "                    'Redskins': 'Washington'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     57,
     65,
     77,
     141,
     212,
     233,
     246,
     299,
     310,
     329,
     345,
     356,
     370,
     384,
     406,
     437,
     445
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initial_538_predictions():\n",
    "    \"\"\"Creates dataframe with initial values from 538\n",
    "    Returns:\n",
    "        dataframe of 538 predictions\n",
    "    \"\"\"\n",
    "    df_columns = ['date', 'team', 'win%']\n",
    "    df = pd.DataFrame(columns=df_columns)\n",
    "    \n",
    "    output_file = 'z:\\python_projects\\aaa.exe'\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://projects.fivethirtyeight.com/2019-nfl-predictions/games/?ex_cid=rrpromo'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "    # Finding year of predictions\n",
    "    for timestamp in soup.findAll('div', attrs={'class': 'container'}):\n",
    "        for year in timestamp.findAll('div', attrs={'id': 'intro'}):\n",
    "            year = int(year.h1.get_text()[0:5])\n",
    "\n",
    "    # Gathering data\n",
    "    for week in soup.findAll('section', attrs={'class': 'week'}):\n",
    "        if week.get_text()[5] == '6':\n",
    "            for date in week.findAll('div', attrs={'class': 'days'}):\n",
    "                for day in date.findAll('div', attrs={'class': 'day'}):  \n",
    "                    for game in day.findAll('div', attrs={'class': 'game'}):\n",
    "\n",
    "                        # Finding date of each game  \n",
    "                        for h4 in day.findAll('h4', attrs={'class': 'h4'}):\n",
    "                            date = h4.get_text().strip()\n",
    "                            date = date.split(', ')[1]\n",
    "                            date = date[0:3] + date[4:] + ' ' + str(year)\n",
    "                            date = datetime.datetime.strptime(date, '%b %d %Y')\n",
    "                            date = date.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "                        # Finding data for each game\n",
    "                        for game_body in game.findAll('table', attrs={'class': 'game-body'}):           \n",
    "                            for num_teams, matchup in enumerate(game_body.findAll('tr', attrs={'class': 'tr'})):\n",
    "                                squad = matchup.find('td', attrs={'class': 'td text team'})\n",
    "                                win_percentage = matchup.find('td', attrs={'class': 'td number chance'}).get_text().strip()\n",
    "\n",
    "                                if squad:\n",
    "                                    team = squad.get_text().strip()\n",
    "                                    result = ''\n",
    "                                    \n",
    "                                    if num_teams == 0:\n",
    "                                        df = df.append(pd.Series([date, team, win_percentage], \n",
    "                                                                  index=df.columns), ignore_index=True)\n",
    "                                    else:\n",
    "                                        df = df.append(pd.Series(['', team, win_percentage], \n",
    "                                                                  index=df.columns), ignore_index=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df, year\n",
    "    \n",
    "def getting_spreadsheet(file_name):\n",
    "    \"\"\"Loads spreadsheet\n",
    "    Args:\n",
    "        file_name: path of file\n",
    "    Returns:\n",
    "        dataframe of data\n",
    "    \"\"\"\n",
    "    return(pd.read_csv(file_name))\n",
    "def separating_games(df):\n",
    "    \"\"\"Separates old games and new games\n",
    "    Args:\n",
    "        df: dataframe of data\n",
    "    Returns:\n",
    "        old_games: games with results already\n",
    "        current_game: games without results\n",
    "    \"\"\"\n",
    "    old_games = df[df['result'] != '']\n",
    "    old_games_index = df[df['result'] != ''].index \n",
    "    current_games = df.drop(old_games_index)\n",
    "    return old_games, current_games\n",
    "def predictions_538(week_num):\n",
    "    \"\"\"Loads 538 predictions\n",
    "    Args:\n",
    "        week_num: week number of games\n",
    "    Returns:\n",
    "        df: dataframe with 538 predictions\n",
    "        year: year of games. Needed for Vegas odds\n",
    "    \"\"\"\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://projects.fivethirtyeight.com/2019-nfl-predictions/games/?ex_cid=rrpromo'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "    cols = ['date', 'team', 'win%']\n",
    "    blank_rows = ['']*(len(df.columns)-3)\n",
    "    cols.extend(blank_rows)\n",
    "    predictions = pd.DataFrame(columns=cols)\n",
    "\n",
    "    # Finding year of predictions\n",
    "    for timestamp in soup.findAll('div', attrs={'class': 'container'}):\n",
    "        for year in timestamp.findAll('div', attrs={'id': 'intro'}):\n",
    "            year = int(year.h1.get_text()[0:5])\n",
    "\n",
    "    # Gathering data\n",
    "    for week in soup.findAll('section', attrs={'class': 'week'}):\n",
    "        if week.get_text()[5] == str(week_num):\n",
    "            for date in week.findAll('div', attrs={'class': 'days'}):\n",
    "                for day in date.findAll('div', attrs={'class': 'day'}):  \n",
    "                    for game in day.findAll('div', attrs={'class': 'game'}):\n",
    "\n",
    "                        # Finding date of each game  \n",
    "                        for h4 in day.findAll('h4', attrs={'class': 'h4'}):\n",
    "                            date = h4.get_text().strip()\n",
    "                            date = date.split(', ')[1]\n",
    "                            date = date[0:3] + date[4:] + ' ' + str(year)\n",
    "                            date = datetime.datetime.strptime(date, '%b %d %Y')\n",
    "                            date = date.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "                        # Finding data for each game\n",
    "                        for game_body in game.findAll('table', attrs={'class': 'game-body'}):           \n",
    "                            for num_teams, matchup in enumerate(game_body.findAll('tr', attrs={'class': 'tr'})):\n",
    "                                squad = matchup.find('td', attrs={'class': 'td text team'})\n",
    "                                win_percentage = matchup.find('td', attrs={'class': 'td number chance'}).get_text().strip()\n",
    "\n",
    "                                if squad:\n",
    "                                    team = squad.get_text().strip()\n",
    "                                    result = ''\n",
    "                                    \n",
    "                                    if num_teams == 0:\n",
    "                                        row_data = [date, team, win_percentage]\n",
    "                                        row_data.extend(blank_rows)\n",
    "                                        \n",
    "                                        predictions = predictions.append(pd.Series(row_data, index=predictions.columns), \n",
    "                                                                         ignore_index=True)\n",
    "                                    else:\n",
    "                                        row_data = ['', team, win_percentage]\n",
    "                                        row_data.extend(blank_rows)\n",
    "\n",
    "                                        predictions = predictions.append(pd.Series(row_data, index=predictions.columns), \n",
    "                                                                         ignore_index=True)\n",
    "  \n",
    "    return predictions, year\n",
    "def loading_odds(df, year):\n",
    "    \"\"\"Loads odds to spreadsheet\n",
    "    Args:\n",
    "        df: dataframe that odds will be written to\n",
    "        year: year that will be used to gather the dates of the games\n",
    "    Returns:\n",
    "        dataframe of datawith odds\n",
    "    \"\"\"\n",
    "    names = ['Open', 'odds','Westgate','MGM Mirage', 'betMGM',\n",
    "             'William Hill', 'CG Technology', 'Circa Sports','Stations']\n",
    "    book = pd.DataFrame(columns=names)\n",
    "    output_file = 'z:\\python_projects\\aaa.exe'\n",
    "    temp_away_list = []\n",
    "    temp_home_list = []\n",
    "    teams_list = []\n",
    "    dates_list = []\n",
    "    URL = 'http://www.vegasinsider.com/nfl/odds/las-vegas/money/'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "    for gameboard in soup.findAll('table', attrs={'class': 'viBodyContainerTble'}):\n",
    "        for num, games in enumerate(gameboard.findAll('td', attrs={'class': 'viBodyBorderNorm'})):\n",
    "            for game_info in games.findAll('td'):  \n",
    "                for date in game_info.findAll('span', attrs={'class': 'cellTextHot'}):\n",
    "                    date = date.get_text().split()[0]\n",
    "                    month = date.split('/')[0]\n",
    "                    day = date.split('/')[1]\n",
    "\n",
    "                    if(int(day[0]) == 0):\n",
    "                        day = day[1:]\n",
    "\n",
    "                    date = str(month) + '/' + str(day) + '/' + str(year)\n",
    "                    dates_list.extend([date, date])\n",
    "\n",
    "                for team_name in game_info.findAll('a', attrs={'class': 'tabletext'}):\n",
    "                    teams_list.append(team_name.get_text())\n",
    "\n",
    "            for num, spread in enumerate(games.findAll('td',attrs={'class': \n",
    "                                                                  ['viCellBg1 cellTextNorm cellBorderL1 center_text nowrap',\n",
    "                                                                   'viCellBg1 cellTextHot cellBorderL1 center_text nowrap',\n",
    "                                                                   'viCellBg2 cellTextNorm cellBorderL1 center_text nowrap',\n",
    "                                                                   'viCellBg2 cellTextHot cellBorderL1 center_text nowrap']})):           \n",
    "                spread_text = spread.get_text().strip()\n",
    "                if spread_text == '' or spread_text == 'XXXX':\n",
    "                    away_spread = np.nan\n",
    "                    home_spread = np.nan\n",
    "                elif(spread_text[4] == '+' or spread_text[4] == '-'):\n",
    "                    away_spread = spread_text[0:4]\n",
    "                    home_spread = spread_text[4:]\n",
    "                else:\n",
    "                    away_spread = spread_text[0:5]\n",
    "                    home_spread = spread_text[5:]\n",
    "\n",
    "                temp_away_list.append(away_spread)\n",
    "                temp_home_list.append(home_spread)\n",
    "                \n",
    "                if len(temp_home_list) == 9:\n",
    "                    book = book.append(pd.Series(temp_away_list, index=names), ignore_index=True)\n",
    "                    book = book.append(pd.Series(temp_home_list, index=names), ignore_index=True)\n",
    "                    temp_away_list = []\n",
    "                    temp_home_list = []\n",
    "\n",
    "    book['team'] = teams_list\n",
    "    book['date'] = dates_list\n",
    "\n",
    "    book = book[book.date <= df.date.max()]    # Only getting odds for games in current week\n",
    "    odds = book[['team', 'odds']]\n",
    "    df = pd.merge(odds, df)[['date', 'team', 'win%', 'odds']]\n",
    "\n",
    "    return df\n",
    "def date_formatter(row):\n",
    "    \"\"\"Loads odds to spreadsheet\n",
    "    Args:\n",
    "        df: dataframe that odds will be written to\n",
    "        year: year that will be used to gather the dates of the games\n",
    "    Returns:\n",
    "        dataframe of datawith odds\n",
    "    \"\"\"\n",
    "    \n",
    "    if row.date == '':\n",
    "        return(row.date)\n",
    "    else:\n",
    "        split_date = row.date.split('/')\n",
    "        day = split_date[1]\n",
    "        day = day.zfill(2)\n",
    "        date = split_date[0] + day + split_date[2]\n",
    "        date = datetime.datetime.strptime(date, '%m%d%Y')\n",
    "        date = date.strftime('%m/%d/%Y')\n",
    "        return(date)\n",
    "            \n",
    "    \n",
    "def combining_data(df_top, df_bottom):\n",
    "    \"\"\"Appends two dataframes\n",
    "    Args:\n",
    "        df_top: dataframe of data to go on top\n",
    "        df_bottom: dataframe of data to go on bottom\n",
    "    Returns:\n",
    "        df: combined dataframe\n",
    "    \"\"\"\n",
    "    cols = df_top.columns\n",
    "    df = pd.concat([df_top, df_bottom], ignore_index=True, )\n",
    "    df = df[cols]\n",
    "    df.replace(np.nan, '', inplace=True)\n",
    "    return(df)\n",
    "def game_outcomes(df, week_num):\n",
    "    \"\"\"Finds winners and losers of games\n",
    "    Args:\n",
    "        df: dataframe of data\n",
    "        week_num: week of games\n",
    "    Returns:\n",
    "        winners, losers: lists of winners and loser of games\n",
    "    \"\"\"\n",
    "    year = 2019\n",
    "    result = ''\n",
    "    URL = 'https://projects.fivethirtyeight.com/2019-nfl-predictions/games/?ex_cid=rrpromo'\n",
    "    headers = {'User-Agent': header_name}\n",
    "    source = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "    winners = []\n",
    "    losers = []\n",
    "\n",
    "    # Finding year of predictions\n",
    "    for timestamp in soup.findAll('div', attrs={'class': 'container'}):\n",
    "        for year in timestamp.findAll('div', attrs={'id': 'intro'}):\n",
    "            year = int(year.h1.get_text()[0:5])\n",
    "\n",
    "    # Gathering data\n",
    "    for week in soup.findAll('section', attrs={'class': 'week'}):\n",
    "        if week.get_text()[5] == str(week_num):\n",
    "            for date in week.findAll('div', attrs={'class': 'days'}):\n",
    "                for day in date.findAll('div', attrs={'class': 'day'}):  \n",
    "                    for game in day.findAll('div', attrs={'class': 'game'}):\n",
    "\n",
    "                        # Finding date of each game  \n",
    "                        for h4 in day.findAll('h4', attrs={'class': 'h4'}):\n",
    "                            date = h4.get_text()\n",
    "                            date = date.split(', ')[1]\n",
    "                            date = date[0:3] + date[4:6] + ' ' + str(year)\n",
    "                            date = datetime.datetime.strptime(date, '%b %d %Y')\n",
    "                            date = date.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "                        # Finding data for each game\n",
    "                        for game_body in game.findAll('table', attrs={'class': 'game-body'}):           \n",
    "                            for num_teams, matchup in enumerate(game_body.findAll('tr', attrs={'class': 'tr'})):\n",
    "                                winner = matchup.find('td', attrs={'class': 'td text team winner'})\n",
    "                                loser = matchup.find('td', attrs={'class': 'td text team loser'})\n",
    "\n",
    "                                if winner:\n",
    "                                    winners.append(winner.get_text().strip())\n",
    "                                elif loser:\n",
    "                                    losers.append(loser.get_text().strip())\n",
    "                                else:\n",
    "                                    continue\n",
    "                                \n",
    "    \n",
    "    return winners, losers\n",
    "def odds_checker(row):\n",
    "    \"\"\"Checks if odds for game are present\n",
    "    Args:\n",
    "        row: row of data\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    if row['odds'] != '':\n",
    "        return(row['odds'])\n",
    "    else:\n",
    "        return(row['odds new'])  \n",
    "def implied_probability(row):\n",
    "    \"\"\"Uses odds to determine implied probability\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        implied win probability if it exists\n",
    "    \"\"\"\n",
    "    if 'implied' in row.index:\n",
    "        return row['implied']\n",
    "    elif row['odds'] == '':\n",
    "        return('')\n",
    "    elif row['odds'][0] == '+':\n",
    "        return(round(100.0/(100+int(row['odds'][1:])), 2))\n",
    "    elif row['odds'][0] == '-':\n",
    "        return(round(int(row['odds'][1:])/(100.0+int(row['odds'][1:])), 2))\n",
    "    else:\n",
    "        return('')    \n",
    "    \n",
    "    \n",
    "def pick(row):\n",
    "    \"\"\"Uses win% and odds to determine what team to pick\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        pick if there is one\n",
    "    \"\"\"\n",
    "    if 'pick' in row.index:\n",
    "        return(row['pick'])\n",
    "    elif row['implied'] == '':\n",
    "        return('')\n",
    "    elif (float(row['win%'][:-1])/100.0 > row['implied']):\n",
    "        return(row.team)\n",
    "    else:\n",
    "        return('')\n",
    "    \n",
    "def spreadsheet_formatter(df):\n",
    "    \"\"\"Formats spreadsheet\n",
    "    Args:\n",
    "        df: dataframe of data\n",
    "\n",
    "    \"\"\"\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "        \n",
    "    df.replace(np.nan, '', inplace=True)\n",
    "    \n",
    "def odds_formatter(row):\n",
    "    \"\"\"Formats odds\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        formatted odds\n",
    "    \"\"\"\n",
    "    if int(row['odds']) >= 100:\n",
    "        return('+' + str(row['odds']))\n",
    "    if int(row['odds']) <= -100:\n",
    "        return(str(row['odds']))\n",
    "    else:\n",
    "        return(str(row['odds'])) \n",
    "    \n",
    "def team_won_lost(row, winners, losers):\n",
    "    \"\"\"Determines team outcomes\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        updated entry for winner/loser\n",
    "    \"\"\"\n",
    "    if row['team'] in winners:\n",
    "        return('w')\n",
    "    elif row['team'] in losers:\n",
    "        return('l')\n",
    "    else:\n",
    "        return('')\n",
    "     \n",
    "def money_won_lost(row):\n",
    "    \"\"\"Determines amount won lost\n",
    "    Args:\n",
    "        row: row of data from dataframe\n",
    "    Returns:\n",
    "        amount won/lost\n",
    "    \"\"\"\n",
    "    if row['pick'] == '':\n",
    "        return(0)\n",
    "    else:\n",
    "        if row['result'] == 'w':\n",
    "            if row['odds'][0] == '+':\n",
    "                return(int(row['odds'][1:]))\n",
    "            else:\n",
    "                return(100)\n",
    "        elif row['result'] == 'l':\n",
    "            if row['odds'][0] == '+':\n",
    "                return(-100)\n",
    "            else:\n",
    "                return(int(row['odds']))\n",
    "        else:\n",
    "            return(0)\n",
    "def week_finder():\n",
    "    \"\"\"Finds what week games are in\n",
    "    Returns:\n",
    "        week: week of games\n",
    "    \"\"\"\n",
    "    if datetime.date.today() < datetime.date(2019, 10, 21):\n",
    "        week = 7\n",
    "    elif datetime.date.today() < datetime.date(2019, 10, 28):\n",
    "        week = 8\n",
    "    elif datetime.date.today() < datetime.date(2019, 11, 4):\n",
    "        week = 9\n",
    "    elif datetime.date.today() < datetime.date(2019, 11, 11):\n",
    "        week = 10\n",
    "    elif datetime.date.today() < datetime.date(2019, 11, 18):\n",
    "        week = 11\n",
    "    elif datetime.date.today() < datetime.date(2019, 11, 25):\n",
    "        week = 12\n",
    "    elif datetime.date.today() < datetime.date(2019, 12, 2):\n",
    "        week = 13\n",
    "    elif datetime.date.today() < datetime.date(2019, 12, 9):\n",
    "        week = 14\n",
    "    elif datetime.date.today() < datetime.date(2019, 12, 16):\n",
    "        week = 15\n",
    "    elif datetime.date.today() < datetime.date(2019, 12, 23):\n",
    "        week = 16\n",
    "    elif datetime.date.today() < datetime.date(2019, 12, 30):\n",
    "        week = 17\n",
    "    else:\n",
    "        week = 0\n",
    "        \n",
    "    return(week)\n",
    "def team_acronym_converter(team_acronyms):\n",
    "    \"\"\"Converts acronym to team name\n",
    "    Args:\n",
    "        acronym: acronym of team\n",
    "    Returns:\n",
    "        name of team\n",
    "    \"\"\"\n",
    "    return team_acronym[acronym]\n",
    "def writing_spreadsheet(df, filename):\n",
    "    \"\"\"Writing to spreadsheet\n",
    "    Args:\n",
    "        df: data\n",
    "        file_name: path of file\n",
    "    \"\"\"\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name = 'z:\\\\python projects\\\\NFL Game Outcome Spreadsheet.csv'\n",
    "\n",
    "df = getting_spreadsheet(file_name) # Retrieving Spreadsheet\n",
    "spreadsheet_formatter(df)\n",
    "old_games, current_games = separating_games(df)\n",
    "\n",
    "current_games['odds'] = current_games.apply(lambda row: odds_formatter(row), axis=1)\n",
    "winners, losers = game_outcomes(current_games, week_num=week_finder()-1)\n",
    "\n",
    "current_games['result'] = current_games.apply(lambda row: team_won_lost(row, winners, losers), axis=1)\n",
    "\n",
    "current_games['w/l'] = current_games.apply(lambda row: money_won_lost(row), axis=1)\n",
    "current_games['total'] = current_games['w/l'].sum()\n",
    "df = combining_data(old_games, current_games)\n",
    "df['date'] = df.apply(lambda row: date_formatter(row), axis=1)\n",
    "\n",
    "if datetime.date.today().strftime('%m/%d/%Y') > df.date.max():\n",
    "    new_games, year = predictions_538(week_num=week_finder())\n",
    "    new_games = loading_odds(new_games, year)\n",
    "    new_games['implied'] = new_games.apply(lambda row: implied_probability(row), axis=1)\n",
    "    new_games['pick'] = new_games.apply(lambda row: pick(row), axis=1)\n",
    "    df = combining_data(df, new_games)\n",
    "\n",
    "df\n",
    "#writing_spreadsheet(df, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_columns = ['date', 'team', 'win%']\n",
    "df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "year = 2019\n",
    "result = ''\n",
    "URL = 'https://www.espn.com/nfl/scoreboard/_/year/2019/seasontype/2/week/6'\n",
    "#URL = 'https://www.espn.com/nfl/game/_/gameId/401128132'\n",
    "headers = {'User-Agent': header_name}\n",
    "source = requests.get(URL, headers=headers)\n",
    "soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "for a in soup.findAll('div', attrs={'class': 'scoreboard-top no-tabs'}):\n",
    "    print(a.get_text())\n",
    "\n",
    "for a in soup.findAll('a', attrs={'class': 'button-alt sm'}):\n",
    "    print(a)\n",
    "#for a in soup.findAll('body'):#, attrs={'class': 'mobileScoreboardLink'}):\n",
    "        #print(a.get_text())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_columns = ['team', 'win%']\n",
    "df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "year = 2019\n",
    "result = ''\n",
    "URL = 'https://www.foxsports.com/nfl/predictions'\n",
    "headers = {'User-Agent': header_name}\n",
    "source = requests.get(URL, headers=headers)\n",
    "soup = BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "for matchup in soup.findAll('div', attrs={'class': 'wisbb_predictionChip'}):\n",
    "    for num, team_name in enumerate(matchup.findAll('span', attrs={'class': 'wisbb_teamName'})):\n",
    "        if num == 0:\n",
    "            away_team = team_name.get_text().strip()\n",
    "        elif num == 1:\n",
    "            home_team = team_name.get_text().strip()\n",
    "        else:\n",
    "            continue\n",
    "        print(away_team)   \n",
    "    for num, predictions in enumerate(matchup.findAll('span', attrs={'class': 'wisbb_predData'})):\n",
    "        prediction_text = predictions.get_text()\n",
    "        team_acronym = predictions.get_text()[0:3].strip()\n",
    "        if team_acronym in team_acronym_dict and len(a)>4 and num ==1:\n",
    "            print(prediction_text)\n",
    "            df = df.append(pd.Series([team_acronym_dict[team_acronym], 1], \n",
    "                                     index=df.columns), ignore_index=True)\n",
    "            \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
